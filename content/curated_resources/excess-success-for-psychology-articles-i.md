
    {
        "Timestamp":"2020-06-08T18:08:58.444Z",
        "Title":"Excess Success for Psychology Articles in the Journal Science",
        "link_to_resource":"https:\/\/doi.org\/10.1371\/journal.pone.0114255",
        "Creators":"Gregory Francis ,Jay Tanzman,William J. Matthews",
        "Material_Type":[
            "Primary Source",
            "Reading",
            "Paper"
        ],
        "Education_Level":[
            "College \/ Upper Division (Undergraduates)"
        ],
        "Abstract":"This article describes a systematic analysis of the relationship between empirical data and theoretical conclusions for a set of experimental psychology articles published in the journal Science between 2005\u20132012. When the success rate of a set of empirical studies is much higher than would be expected relative to the experiments\u2019 reported effects and sample sizes, it suggests that null findings have been suppressed, that the experiments or analyses were inappropriate, or that the theory does not properly follow from the data. The analyses herein indicate such excess success for 83% (15 out of 18) of the articles in Science that report four or more studies and contain sufficient information for the analysis. This result suggests a systematic pattern of excess success among psychology articles in the journal Science.",
        "Language":"English",
        "Conditions_of_Use":"I don't see any of these",
        "Primary_User":[
            "Student"
        ],
        "Subject_Areas":[
            "Applied Science",
            "Social Science"
        ],
        "FORRT_Clusters":[
            "Reproducibility and Replicability Knowledge",
            "Replication Research"
        ],
        "Tags":[
            "Reproducibility Crisis and Credibility Revolution",
            "Open Science"
        ]
    }
