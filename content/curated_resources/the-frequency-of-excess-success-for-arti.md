
    {
        "Timestamp":"2020-05-28T13:01:48.975Z",
        "Title":"The frequency of excess success for articles in Psychological Science.",
        "link_to_resource":"https:\/\/doi.org\/10.3758\/s13423-014-0601-x",
        "Creators":"Gregory Francis",
        "Material_Type":[
            "Primary Source",
            "Reading",
            "Paper"
        ],
        "Education_Level":[
            "College \/ Upper Division (Undergraduates)"
        ],
        "Abstract":"Recent controversies have questioned the quality of scientific practice in the field of psychology, but these concerns are often based on anecdotes and seemingly isolated cases. To gain a broader perspective, this article applies an objective test for excess success to a large set of articles published in the journal Psychological Science between 2009 and 2012. When empirical studies succeed at a rate much higher than is appropriate for the estimated effects and sample sizes, readers should suspect that unsuccessful findings have been suppressed, the experiments or analyses were improper, or the theory does not properly account for the data. In total, problems appeared for 82 % (36 out of 44) of the articles in Psychological Science that had four or more experiments and could be analyzed.",
        "Language":"English",
        "Conditions_of_Use":"I don't see any of these",
        "Primary_User":[
            "Student"
        ],
        "Subject_Areas":[
            "Applied Science",
            "Social Science"
        ],
        "FORRT_Clusters":[
            "Reproducibility and Replicability Knowledge",
            "Replication Research"
        ],
        "Tags":[
            "Reproducibility Crisis and Credibility Revolution",
            "Open Science"
        ]
    }
